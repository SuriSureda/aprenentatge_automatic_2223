{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pylab as pl\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dades\n",
    "\n",
    "Emprarem la Versió de 2012 de la base de dades PASCAL VOC [enllaç](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html) un dels conjunts de dades més coneguts. Nosaltres només en farem una petita exploració.\n",
    "\n",
    "En aquest cas les etiquetes són a les imatges, és a dir la _label_ d'una imatge és una altra imatge d'un sol canal on cada pixel pot tenir 3 tipus de valor:\n",
    "\n",
    "- 0: valor del fons\n",
    "- 1 a 24: és un valor que indica que el pixel pertany a una classe (mirar la web del conjunt de dades)\n",
    "- 255: pixel no etiquetat.\n",
    "\n",
    "\n",
    "**Feina**\n",
    "\n",
    "Carregar el conjunt de dades i seleccionar totes les imatges que contenen un moix (categoria _cat_). Per cada imatge que conté un moix, heu de posar tots els pixels que no són d'un moix de la imatge _label_ a 0 i els que són d'un moix a 1.\n",
    "\n",
    "També heu de canviar la mida de les imatges a la següent dimensionalitat: $224x224$.\n",
    "\n",
    "_Recomanació_: Abans de posar-vos a filtrar imatges inspeccionau els valors que aquestes tenen, la funció `np.unique` us pot servir d'ajuda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creating the dataset\n",
    "train_dataset = datasets.VOCSegmentation(\n",
    "    './datasets/',\n",
    "    year='2012',\n",
    "    download=True,\n",
    "    image_set='train',\n",
    "    transform=XXXX, #TODO \n",
    ")\n",
    "\n",
    "valid_dataset = datasets.VOCSegmentation(\n",
    "    './datasets/',\n",
    "    year='2012',\n",
    "    download=True,\n",
    "    image_set='val',\n",
    "    transform=XXXX, #TODO\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16 # no canviar\n",
    " #TODO \n",
    "train_loader = DataLoader(XXXX, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=2)\n",
    "valid_loader = DataLoader(XXXX, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feina a fer**\n",
    "\n",
    "Un cop teniu els conjunts de dades creats heu de comprovar que les imatges que es corresponen amb les etiquetes tenen la informació correcta, feis una visualització."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definició de la xarxa\n",
    "\n",
    "Podem observar com es pot emprar l'orientació a objectes de **Python** per crear una xarxa de manera ordenada, és interessant analitzar aquest codi amb detall ja que en podem aprendre molt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Credits: https://github.com/mateuszbuda/brain-segmentation-pytorch\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, out_channels=1, init_features=32):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        features = init_features\n",
    "        \n",
    "        ## CODER\n",
    "        self.encoder1 = UNet._block(in_channels, features, name=\"enc1\")\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder2 = UNet._block(features, features * 2, name=\"enc2\")\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder3 = UNet._block(features * 2, features * 4, name=\"enc3\")\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.encoder4 = UNet._block(features * 4, features * 8, name=\"enc4\")\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.bottleneck = UNet._block(features * 8, features * 16, name=\"bottleneck\")\n",
    "        \n",
    "        ## DECODER\n",
    "        self.upconv4 = nn.ConvTranspose2d(features * 16, features * 8, kernel_size=2, stride=2)\n",
    "        self.decoder4 = UNet._block((features * 8) * 2, features * 8, name=\"dec4\")\n",
    "        \n",
    "        self.upconv3 = nn.ConvTranspose2d(features * 8, features * 4, kernel_size=2, stride=2)\n",
    "        self.decoder3 = UNet._block((features * 4) * 2, features * 4, name=\"dec3\")\n",
    "        \n",
    "        self.upconv2 = nn.ConvTranspose2d(features * 4, features * 2, kernel_size=2, stride=2)\n",
    "        self.decoder2 = UNet._block((features * 2) * 2, features * 2, name=\"dec2\")\n",
    "        \n",
    "        self.upconv1 = nn.ConvTranspose2d(features * 2, features, kernel_size=2, stride=2)\n",
    "        self.decoder1 = UNet._block(features * 2, features, name=\"dec1\")\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=features, out_channels=out_channels, kernel_size=1)\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(self.pool1(enc1))\n",
    "        enc3 = self.encoder3(self.pool2(enc2))\n",
    "        enc4 = self.encoder4(self.pool3(enc3))\n",
    "\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "\n",
    "        dec4 = self.upconv4(bottleneck)\n",
    "\n",
    "        dec4 = torch.cat((dec4, enc4), dim=1)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        \n",
    "        dec3 = self.upconv3(dec4)\n",
    "        dec3 = torch.cat((dec3, enc3), dim=1)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        \n",
    "        dec2 = self.upconv2(dec3)\n",
    "        dec2 = torch.cat((dec2, enc2), dim=1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        \n",
    "        dec1 = self.upconv1(dec2)\n",
    "        dec1 = torch.cat((dec1, enc1), dim=1)\n",
    "        dec1 = self.decoder1(dec1)\n",
    "        \n",
    "        return torch.sigmoid(self.conv(dec1))\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def _block(in_channels, features, name):\n",
    "        return nn.Sequential(\n",
    "            OrderedDict(\n",
    "                [\n",
    "                    (name + \"conv1\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=in_channels,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm1\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu1\", nn.ReLU(inplace=True)),\n",
    "                    (name + \"conv2\",\n",
    "                        nn.Conv2d(\n",
    "                            in_channels=features,\n",
    "                            out_channels=features,\n",
    "                            kernel_size=3,\n",
    "                            padding=1,\n",
    "                            bias=False,\n",
    "                        ),\n",
    "                    ),\n",
    "                    (name + \"norm2\", nn.BatchNorm2d(num_features=features)),\n",
    "                    (name + \"relu2\", nn.ReLU(inplace=True)),\n",
    "                ]\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenament\n",
    "\n",
    "Per fer tasques de segmentació, una de les funcions de pèrdua que podem emprar és el _Diceloss_ (intersecció vs unió)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = 0.0\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        assert y_pred.size() == y_true.size()\n",
    "        y_pred = y_pred[:, 0].contiguous().view(-1)\n",
    "        y_true = y_true[:, 0].contiguous().view(-1)\n",
    "        intersection = (y_pred * y_true).sum()\n",
    "        dsc = (2. * intersection + self.smooth) / (\n",
    "            y_pred.sum() + y_true.sum() + self.smooth\n",
    "        )\n",
    "        return 1. - dsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El bucle d'entrenament és diferent al que estau acostumats a veure en l'assignatura, s'assembla molt més als propis tutorials de _Pytorch_.\n",
    "\n",
    "A més s'aprofita per introduir la visualització de resultats de forma dinàmica usant la llibreria [tqdm](https://github.com/tqdm/tqdm) i la llibreria _matplotlib_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "model = UNet().to(device)\n",
    "\n",
    "optim = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = DiceLoss() \n",
    "\n",
    "t_loss = np.zeros((num_epochs))\n",
    "v_loss = np.zeros((num_epochs))\n",
    "\n",
    "pbar = tqdm(range(1, num_epochs+1)) # tdqm permet tenir text dinàmic\n",
    "\n",
    "for epoch in pbar:\n",
    "    \n",
    "    train_loss = 0 \n",
    "    val_loss = 0  \n",
    "    \n",
    "    model.train()                                                  \n",
    "    for batch_num, (input_img, target) in enumerate(train_loader, 1):   \n",
    "        input_img= input_img.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = model(input_img)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()                                            \n",
    "        optim.step()                                               \n",
    "        optim.zero_grad()     \n",
    "        \n",
    "        train_loss += loss.item()    \n",
    "                                                       \n",
    "    model.eval()   \n",
    "    with torch.no_grad():                                          \n",
    "        for input_img, target in valid_loader: \n",
    "            input_img = input_img.to(device)\n",
    "            target = target.to(device)\n",
    "            \n",
    "            output = model(input_img)                                   \n",
    "            loss = criterion(output, target)   \n",
    "            val_loss += loss.item()  \n",
    "    \n",
    "    # RESULTATS\n",
    "    train_loss /= len(train_loader)\n",
    "    t_loss[epoch-1] = train_loss\n",
    "    \n",
    "    val_loss /= len(valid_loader)   \n",
    "    v_loss[epoch-1] = val_loss\n",
    "    \n",
    "    # VISUALITZACIO DINAMICA\n",
    "    plt.figure(figsize=(10,5))\n",
    "    pl.plot(t_loss[:epoch-1], label=\"train\")\n",
    "    pl.plot(v_loss[:epoch-1], label=\"validation\")\n",
    "    pl.legend()\n",
    "    pl.xlim(0,num_epochs)\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())\n",
    "    plt.close()\n",
    "\n",
    "    pbar.set_description(f\"Epoch:{epoch} Training Loss:{train_loss} Validation Loss:{val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardam el model, d'aquesta manera no es necessari fer l'entrenament a classe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-64de258bcead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unet_pascal.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"unet_pascal.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluació"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregam el model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmodel =  UNet().to(device)\n",
    "mmodel.load_state_dict(torch.load(\"unet_pascal.pt\"))\n",
    "mmodel.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feina a fer**\n",
    "\n",
    "Visualitzar exemples de segmentació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
